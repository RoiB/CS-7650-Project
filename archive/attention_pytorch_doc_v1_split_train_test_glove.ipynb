{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "attention pytorch doc v1 split train test glove.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "71L6TP2rbKVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXy9KkPbbS3I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_hwXi0sched",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_1OyHxAcjN3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open('%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "#     pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "    pairs = []\n",
        "    for l in lines:\n",
        "        pairs.append([normalizeString(s) for s in l.split('\\t')[:2]])\n",
        "#     print(pairs)\n",
        "    random.shuffle(pairs)\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "    \n",
        "    # # split test/training\n",
        "    # pairs_test = pairs[int(0.8*len(pairs)):]\n",
        "    # pairs = pairs[:int(0.8*len(pairs))]\n",
        "    # return input_lang, output_lang, pairs, pairs_test\n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmo4j63YclmZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 100\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bU11fGkjdIi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "2d84a0f3-f3a3-42da-b52e-99a0d484122b"
      },
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    # input_lang, output_lang, pairs, pairs_test = readLangs(lang1, lang2, reverse)\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "\n",
        "    pairs_test = pairs[int(0.8*len(pairs)):]\n",
        "    pairs = pairs[:int(0.8*len(pairs))]    \n",
        "    return input_lang, output_lang, pairs, pairs_test\n",
        "\n",
        "\n",
        "input_lang, output_lang, pairs, pairs_test = prepareData('eng', 'label', reverse=False)\n",
        "print(random.choice(pairs))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "Read 6843 sentence pairs\n",
            "Trimmed to 6842 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "eng 23197\n",
            "label 4\n",
            "['the original idea favoured by groves was that the british scientists would work as a group under chadwick who would farm out work to them .', 'neutral']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MbCsen-dgNn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyGwebEOdia6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CtQ1Xgkdkyc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "teacher_forcing_ratio = 0\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVH0mBYYdm_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CX0CRKf9dohr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "            print('eval: ',evaluateRandomlyStats(encoder, decoder, n=1000)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbCJCvfesjAa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluateRandomlyStats(encoder, decoder, n=10):\n",
        "    n_correct = 0\n",
        "    for i in range(n):    \n",
        "        # pair = random.choice(pairs_test)\n",
        "        pair = pairs_test[i]\n",
        "        # pair = random.choice(pairs)\n",
        "        # print('>', pair[0])\n",
        "        # print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        # print('<', output_sentence)\n",
        "        if pair[1] in output_sentence:\n",
        "          n_correct+=1\n",
        "          # print('correct')\n",
        "        # print('')\n",
        "    return 1.*n_correct/n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Avx759DFA_fC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare glove 1\n",
        "import numpy as np\n",
        "words = []\n",
        "word2idx = {}\n",
        "vectors = []\n",
        "\n",
        "glove_size = 100\n",
        "with open(f'./glove.6B.{glove_size}d.txt', 'rb') as f:\n",
        "    for idx,l in enumerate(f):\n",
        "        line = l.decode().split()\n",
        "        word = line[0]\n",
        "        words.append(word)\n",
        "        word2idx[word] = idx\n",
        "        vectors.append(np.array(line[1:]).astype(np.float))\n",
        "glove = {w: vectors[word2idx[w]] for w in words}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWvo4ajHCZ6n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5e1d8a91-0313-4be4-9af8-29b9838b6db0"
      },
      "source": [
        "# prepare glove embedding 2\n",
        "\n",
        "vocab_size = input_lang.n_words\n",
        "weight_matrix = np.zeros((vocab_size, glove_size))\n",
        "\n",
        "words_found = 0\n",
        "for i, word in enumerate(input_lang.word2count.keys()):\n",
        "  \n",
        "  try:\n",
        "    weight_matrix[i] = glove[word]\n",
        "    words_found += 1\n",
        "  except KeyError as e:\n",
        "    # print('Key Error', e)\n",
        "    weight_matrix[i] = np.random.normal(scale=0.6, size=(glove_size, ))\n",
        "\n",
        "print(\"vocab_size\", vocab_size)\n",
        "print(\"words found\",words_found)\n",
        "weights = torch.from_numpy(weight_matrix)\n",
        "print('weight_matrix size',weights.size())"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab_size 23197\n",
            "words found 21604\n",
            "weight_matrix size torch.Size([23197, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYhJ6En9AVkz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderRNN_Glove(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, weights):\n",
        "        super(EncoderRNN_Glove, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        # self.embedding.load_state_dict({'weight':weight_matrix})\n",
        "        self.embedding.weights = nn.Parameter(weights,requires_grad=False)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbL-VC9iuTew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOWVejtVd4Dj",
        "colab_type": "code",
        "outputId": "3ce667c7-748b-4a26-e4df-75a299f1950f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# hidden_size = 256\n",
        "# encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "hidden_size = glove_size\n",
        "encoder1 = EncoderRNN_Glove(input_lang.n_words, hidden_size, weights).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, 100000, print_every=1000,learning_rate=0.03)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0m 30s (- 51m 1s) (1000 1%) 0.3111\n",
            "eval:  0.725\n",
            "1m 3s (- 51m 49s) (2000 2%) 0.3037\n",
            "eval:  0.725\n",
            "1m 36s (- 51m 51s) (3000 3%) 0.3007\n",
            "eval:  0.725\n",
            "2m 8s (- 51m 23s) (4000 4%) 0.2889\n",
            "eval:  0.725\n",
            "2m 40s (- 50m 49s) (5000 5%) 0.2935\n",
            "eval:  0.725\n",
            "3m 13s (- 50m 34s) (6000 6%) 0.2997\n",
            "eval:  0.727\n",
            "3m 47s (- 50m 24s) (7000 7%) 0.2829\n",
            "eval:  0.728\n",
            "4m 20s (- 49m 54s) (8000 8%) 0.2883\n",
            "eval:  0.733\n",
            "4m 53s (- 49m 26s) (9000 9%) 0.2783\n",
            "eval:  0.727\n",
            "5m 26s (- 48m 56s) (10000 10%) 0.2854\n",
            "eval:  0.718\n",
            "5m 58s (- 48m 23s) (11000 11%) 0.2637\n",
            "eval:  0.719\n",
            "6m 31s (- 47m 53s) (12000 12%) 0.2655\n",
            "eval:  0.717\n",
            "7m 4s (- 47m 20s) (13000 13%) 0.2587\n",
            "eval:  0.728\n",
            "7m 37s (- 46m 49s) (14000 14%) 0.2701\n",
            "eval:  0.696\n",
            "8m 9s (- 46m 12s) (15000 15%) 0.2439\n",
            "eval:  0.723\n",
            "8m 42s (- 45m 42s) (16000 16%) 0.2396\n",
            "eval:  0.658\n",
            "9m 16s (- 45m 17s) (17000 17%) 0.2522\n",
            "eval:  0.734\n",
            "9m 49s (- 44m 44s) (18000 18%) 0.2479\n",
            "eval:  0.729\n",
            "10m 22s (- 44m 12s) (19000 19%) 0.2421\n",
            "eval:  0.707\n",
            "10m 54s (- 43m 38s) (20000 20%) 0.2334\n",
            "eval:  0.728\n",
            "11m 26s (- 43m 3s) (21000 21%) 0.2094\n",
            "eval:  0.727\n",
            "11m 59s (- 42m 32s) (22000 22%) 0.2089\n",
            "eval:  0.744\n",
            "12m 32s (- 41m 59s) (23000 23%) 0.2135\n",
            "eval:  0.742\n",
            "13m 4s (- 41m 24s) (24000 24%) 0.1937\n",
            "eval:  0.74\n",
            "13m 37s (- 40m 51s) (25000 25%) 0.1987\n",
            "eval:  0.748\n",
            "14m 9s (- 40m 18s) (26000 26%) 0.1888\n",
            "eval:  0.721\n",
            "14m 42s (- 39m 47s) (27000 27%) 0.1701\n",
            "eval:  0.747\n",
            "15m 16s (- 39m 16s) (28000 28%) 0.1826\n",
            "eval:  0.76\n",
            "15m 49s (- 38m 45s) (29000 28%) 0.1517\n",
            "eval:  0.736\n",
            "16m 23s (- 38m 14s) (30000 30%) 0.1591\n",
            "eval:  0.683\n",
            "16m 55s (- 37m 40s) (31000 31%) 0.1465\n",
            "eval:  0.751\n",
            "17m 29s (- 37m 9s) (32000 32%) 0.1526\n",
            "eval:  0.679\n",
            "18m 1s (- 36m 35s) (33000 33%) 0.1320\n",
            "eval:  0.744\n",
            "18m 34s (- 36m 3s) (34000 34%) 0.1586\n",
            "eval:  0.726\n",
            "19m 7s (- 35m 31s) (35000 35%) 0.1320\n",
            "eval:  0.745\n",
            "19m 40s (- 34m 58s) (36000 36%) 0.1324\n",
            "eval:  0.75\n",
            "20m 13s (- 34m 26s) (37000 37%) 0.1168\n",
            "eval:  0.743\n",
            "20m 48s (- 33m 56s) (38000 38%) 0.1339\n",
            "eval:  0.737\n",
            "21m 20s (- 33m 22s) (39000 39%) 0.1144\n",
            "eval:  0.7\n",
            "21m 53s (- 32m 49s) (40000 40%) 0.1026\n",
            "eval:  0.75\n",
            "22m 25s (- 32m 16s) (41000 41%) 0.1021\n",
            "eval:  0.689\n",
            "22m 58s (- 31m 44s) (42000 42%) 0.1089\n",
            "eval:  0.735\n",
            "23m 31s (- 31m 10s) (43000 43%) 0.0989\n",
            "eval:  0.746\n",
            "24m 4s (- 30m 38s) (44000 44%) 0.0901\n",
            "eval:  0.743\n",
            "24m 36s (- 30m 5s) (45000 45%) 0.1006\n",
            "eval:  0.734\n",
            "25m 10s (- 29m 32s) (46000 46%) 0.0851\n",
            "eval:  0.748\n",
            "25m 43s (- 29m 0s) (47000 47%) 0.0796\n",
            "eval:  0.757\n",
            "26m 16s (- 28m 27s) (48000 48%) 0.0714\n",
            "eval:  0.717\n",
            "26m 49s (- 27m 55s) (49000 49%) 0.0736\n",
            "eval:  0.745\n",
            "27m 22s (- 27m 22s) (50000 50%) 0.0859\n",
            "eval:  0.725\n",
            "27m 55s (- 26m 49s) (51000 51%) 0.0680\n",
            "eval:  0.728\n",
            "28m 28s (- 26m 17s) (52000 52%) 0.0790\n",
            "eval:  0.731\n",
            "29m 2s (- 25m 44s) (53000 53%) 0.0423\n",
            "eval:  0.742\n",
            "29m 34s (- 25m 11s) (54000 54%) 0.0700\n",
            "eval:  0.745\n",
            "30m 8s (- 24m 39s) (55000 55%) 0.0544\n",
            "eval:  0.751\n",
            "30m 41s (- 24m 6s) (56000 56%) 0.0514\n",
            "eval:  0.77\n",
            "31m 15s (- 23m 34s) (57000 56%) 0.0262\n",
            "eval:  0.738\n",
            "31m 49s (- 23m 2s) (58000 57%) 0.0330\n",
            "eval:  0.749\n",
            "32m 23s (- 22m 30s) (59000 59%) 0.0379\n",
            "eval:  0.704\n",
            "32m 56s (- 21m 57s) (60000 60%) 0.0454\n",
            "eval:  0.716\n",
            "33m 29s (- 21m 24s) (61000 61%) 0.0480\n",
            "eval:  0.75\n",
            "34m 3s (- 20m 52s) (62000 62%) 0.0469\n",
            "eval:  0.719\n",
            "34m 37s (- 20m 20s) (63000 63%) 0.0347\n",
            "eval:  0.768\n",
            "35m 11s (- 19m 47s) (64000 64%) 0.0591\n",
            "eval:  0.748\n",
            "35m 44s (- 19m 14s) (65000 65%) 0.0648\n",
            "eval:  0.745\n",
            "36m 18s (- 18m 42s) (66000 66%) 0.0624\n",
            "eval:  0.749\n",
            "36m 52s (- 18m 9s) (67000 67%) 0.0527\n",
            "eval:  0.761\n",
            "37m 26s (- 17m 37s) (68000 68%) 0.0329\n",
            "eval:  0.754\n",
            "38m 1s (- 17m 4s) (69000 69%) 0.0418\n",
            "eval:  0.747\n",
            "38m 34s (- 16m 32s) (70000 70%) 0.0336\n",
            "eval:  0.756\n",
            "39m 8s (- 15m 59s) (71000 71%) 0.0394\n",
            "eval:  0.758\n",
            "39m 42s (- 15m 26s) (72000 72%) 0.0289\n",
            "eval:  0.747\n",
            "40m 16s (- 14m 53s) (73000 73%) 0.0179\n",
            "eval:  0.753\n",
            "40m 48s (- 14m 20s) (74000 74%) 0.0274\n",
            "eval:  0.75\n",
            "41m 21s (- 13m 47s) (75000 75%) 0.0224\n",
            "eval:  0.732\n",
            "41m 53s (- 13m 13s) (76000 76%) 0.0266\n",
            "eval:  0.724\n",
            "42m 25s (- 12m 40s) (77000 77%) 0.0417\n",
            "eval:  0.727\n",
            "42m 56s (- 12m 6s) (78000 78%) 0.0273\n",
            "eval:  0.744\n",
            "43m 28s (- 11m 33s) (79000 79%) 0.0329\n",
            "eval:  0.749\n",
            "44m 0s (- 11m 0s) (80000 80%) 0.0345\n",
            "eval:  0.726\n",
            "44m 31s (- 10m 26s) (81000 81%) 0.0352\n",
            "eval:  0.718\n",
            "45m 2s (- 9m 53s) (82000 82%) 0.0297\n",
            "eval:  0.749\n",
            "45m 33s (- 9m 19s) (83000 83%) 0.0222\n",
            "eval:  0.751\n",
            "46m 5s (- 8m 46s) (84000 84%) 0.0289\n",
            "eval:  0.749\n",
            "46m 38s (- 8m 13s) (85000 85%) 0.0307\n",
            "eval:  0.743\n",
            "47m 8s (- 7m 40s) (86000 86%) 0.0432\n",
            "eval:  0.714\n",
            "47m 39s (- 7m 7s) (87000 87%) 0.0266\n",
            "eval:  0.728\n",
            "48m 10s (- 6m 34s) (88000 88%) 0.0273\n",
            "eval:  0.742\n",
            "48m 41s (- 6m 1s) (89000 89%) 0.0237\n",
            "eval:  0.737\n",
            "49m 13s (- 5m 28s) (90000 90%) 0.0270\n",
            "eval:  0.737\n",
            "49m 44s (- 4m 55s) (91000 91%) 0.0221\n",
            "eval:  0.732\n",
            "50m 15s (- 4m 22s) (92000 92%) 0.0280\n",
            "eval:  0.731\n",
            "50m 47s (- 3m 49s) (93000 93%) 0.0369\n",
            "eval:  0.726\n",
            "51m 19s (- 3m 16s) (94000 94%) 0.0203\n",
            "eval:  0.723\n",
            "51m 51s (- 2m 43s) (95000 95%) 0.0319\n",
            "eval:  0.746\n",
            "52m 22s (- 2m 10s) (96000 96%) 0.0236\n",
            "eval:  0.731\n",
            "52m 54s (- 1m 38s) (97000 97%) 0.0309\n",
            "eval:  0.739\n",
            "53m 25s (- 1m 5s) (98000 98%) 0.0233\n",
            "eval:  0.722\n",
            "53m 56s (- 0m 32s) (99000 99%) 0.0206\n",
            "eval:  0.725\n",
            "54m 27s (- 0m 0s) (100000 100%) 0.0232\n",
            "eval:  0.751\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tyQLgvnwVbS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYR7SocDwXry",
        "colab_type": "code",
        "outputId": "37364fea-c1f0-43e6-bc6d-b5ad0da65659",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        }
      },
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> in frisch moved to london to work with chadwick and his cyclotron .\n",
            "= neutral\n",
            "< neutral <EOS>\n",
            "\n",
            "> after lindsay tries to escape and fails heiter explains that he had previously experimented with creating what he called a three dog also joined mouth to anus .\n",
            "= neutral\n",
            "< neutral <EOS>\n",
            "\n",
            "> from the attack by custer murdering over cherokee women and children at the ouachita river in oklahoma until a bombing of the alfred p . murrah federal building in oklahoma city oklahoma quantrill s raid was the single bloodiest act of domestic terrorism in america .\n",
            "= biased\n",
            "< biased <EOS>\n",
            "\n",
            "> oceanic and atmospheric gyres were able to strengthen in the subtropical atlantic allowing southward advection of cold air and water .\n",
            "= neutral\n",
            "< neutral <EOS>\n",
            "\n",
            "> he concluded the letters by describing himself as the commander of kansas first guerrillas and requesting that local newspapers publish his replies .\n",
            "= neutral\n",
            "< neutral <EOS>\n",
            "\n",
            "> downstream from the villages approximately minutes flying time just out of the west side boys visual and hearing range the helicopters went into a holding pattern to allow the sas observation teams time to get into position to prevent the west side boys from attacking any of the captives before the extraction teams were on the ground .\n",
            "= neutral\n",
            "< neutral <EOS>\n",
            "\n",
            ">  confusion is a commentary on the confused state of post colonial lagos and its lack of infrastructure and proper leadership at the time .\n",
            "= neutral\n",
            "< neutral <EOS>\n",
            "\n",
            "> by the s jews were a major political factor in new york city with strong support for the most liberal programs of the new deal .\n",
            "= biased\n",
            "< biased <EOS>\n",
            "\n",
            "> he included mankind in his speculations from the outset and on seeing an orangutan in the zoo on march noted its childlike behaviour .\n",
            "= neutral\n",
            "< neutral <EOS>\n",
            "\n",
            "> moreover when the stockmarket crashed in much of this growth was destroyed it had been largely based on rising stockmarket valuations not genuine productive capacity .\n",
            "= biased\n",
            "< biased <EOS>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2u_2HjhZ4Diq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluateRandomlyStats(encoder, decoder, n=10):\n",
        "    n_correct = 0\n",
        "    for i in range(n):    \n",
        "        # pair = random.choice(pairs_test)\n",
        "        pair = pairs_test[i]\n",
        "        # pair = random.choice(pairs)\n",
        "        # print('>', pair[0])\n",
        "        # print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        # print('<', output_sentence)\n",
        "        if pair[1] in output_sentence:\n",
        "          n_correct+=1\n",
        "          # print('correct')\n",
        "        # print('')\n",
        "    return 1.*n_correct/n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER5uWxMEwZPG",
        "colab_type": "code",
        "outputId": "ab232155-dfa4-4fb3-bd75-e24f44b9d933",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "evaluateRandomlyStats(encoder1, attn_decoder1, n=1000)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.707"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMP-NMw24nqs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}